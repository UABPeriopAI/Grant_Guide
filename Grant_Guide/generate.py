from langchain.vectorstores import FAISS

import Grant_Guide.prompts as grant_guide_prompts
import Grant_Guide_config.config as grant_helper_config


def search_grant_guide_vectorstore(
    query: str,
    embeddings=None,
    store=grant_helper_config.GRANT_VECTORSTORE,
):
    """
    This function searches for relevant documents in a vectorstore using a query.

    Args:
      query: The search query that you want to use to retrieve relevant documents from the vectorstore.
      embeddings: The embeddings parameter is a variable that contains the path to the file that stores
    the pre-trained word embeddings. These embeddings are used to represent words as vectors in a
    high-dimensional space.
      store: The `store` parameter is a path to the directory where the vector store is saved. This
    vector store contains pre-computed embeddings for a set of documents.

    Returns:
      a list of relevant documents based on the input query, using a vectorstore and embeddings
    specified in the configuration.
    """
    # Load vectorstore
    vectordb = FAISS.load_local(store, embeddings, allow_dangerous_deserialization=True)
    docsearch = vectordb.as_retriever()
    docs = docsearch.get_relevant_documents(query)
    return docs


def get_grant_guide_response(
    query: str,
    docs,
    chat=None,
    chat_prompt=grant_guide_prompts.grant_guide_chat_prompt,
):
    """
    This function takes a query and a list of documents, prompts the user for a response using a
    chatbot, and returns the response.

    Args:
      query: The user's query or question that they want the model to respond to.
      docs: The `docs` parameter is a context or a list of documents that the model will use to generate
    a response to the given query. It can be any relevant information that the model can use to
    understand the context of the query and provide a more accurate response.
      chat: The chatbot model that will generate a response to the given query and context.
      chat_prompt: `chat_prompt` is a string that contains a placeholder for the context and question.
    It is used to prompt the user for a response in a chatbot conversation. The `format_prompt` method
    replaces the placeholders with the actual context and question before sending the prompt to the
    user.

    Returns:
      The function `get_model_response` takes in a query and a list of documents, and uses a chatbot
    model to generate a response to the query based on the context of the documents. The function
    returns the response generated by the chatbot model.
    """
    response = chat(chat_prompt.format_prompt(context=docs, idea=query).to_messages())
    return response


def get_aims_response(
    aims: str, 
    chat=None, 
    chat_prompt=grant_guide_prompts.aims_chat_prompt
):
    """
    The function `get_aims_response` takes an aims string as input and uses a chat function to generate
    a response based on the aims.

    Args:
      aims (str): A string representing the aims or goals for a grant application.
      chat: The `chat` parameter is a function that takes a chat prompt as input and returns a response.
    It is used to simulate a conversation with a chatbot or virtual assistant.
      chat_prompt: The `chat_prompt` parameter is a string that represents the prompt for the chatbot.
    It is used to provide context or instructions to the chatbot before asking a question or making a
    request. In this case, the `chat_prompt` is a formatted string that includes a placeholder `{query}`
    for

    Returns:
      the response from the chatbot.
    """
    response = chat(chat_prompt.format_prompt(query=aims).to_messages())
    return response


def get_strategy_response(
    bullet_points: str,
    rs_part: str,
    instructions: str,
    chat=None,
    chat_prompt=grant_guide_prompts.strategy_chat_prompt,
):
    """
    The function `get_aims_response` takes an aims string as input and uses a chat function to generate
    a response based on the aims.

    Args:
      aims (str): A string representing the aims or goals for a grant application.
      chat: The `chat` parameter is a function that takes a chat prompt as input and returns a response.
    It is used to simulate a conversation with a chatbot or virtual assistant.
      chat_prompt: The `chat_prompt` parameter is a string that represents the prompt for the chatbot.
    It is used to provide context or instructions to the chatbot before asking a question or making a
    request. In this case, the `chat_prompt` is a formatted string that includes a placeholder `{query}`
    for

    Returns:
      the response from the chatbot.
    """
    response = chat(
        chat_prompt.format_prompt(
            bullets=bullet_points, part=rs_part, part_instructions=instructions
        ).to_messages()
    )
    return response


def get_summary_response(
    aims_page: str,
    chat=None,
    chat_prompt=grant_guide_prompts.summary_chat_prompt,
):

    response = chat(chat_prompt.format_prompt(sa_page=aims_page).to_messages())
    return response
